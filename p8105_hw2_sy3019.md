p8105_hw2_sy3019
================
Soungbin Yim
2022-10-04

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6     ✔ purrr   0.3.4
    ## ✔ tibble  3.1.8     ✔ dplyr   1.0.9
    ## ✔ tidyr   1.2.0     ✔ stringr 1.4.1
    ## ✔ readr   2.1.2     ✔ forcats 0.5.2
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(lubridate)
```

    ## 
    ## Attaching package: 'lubridate'
    ## 
    ## The following objects are masked from 'package:base':
    ## 
    ##     date, intersect, setdiff, union

### Problem 1

Below we import and clean data from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with
data import, updates variable names, and selects the columns that will
be used in later parts fo this problem. We update `entry` from `yes` /
`no` to a logical variable. As part of data import, we specify that
`Route` columns 8-11 should be character for consistency with 1-7.

``` r
trans_ent = 
  read_csv(
    "NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations.

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows
    ## # ℹ Use `print(n = ...)` to see more rows

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows
    ## # ℹ Use `print(n = ...)` to see more rows

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows
    ## # ℹ Use `print(n = ...)` to see more rows

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

\##Problem 2

``` r
mr_trash_df <- read_excel("Trash Wheel Collection Data.xlsx",
                       sheet = "Mr. Trash Wheel",
                       range = "A2:N550",
                       col_names = TRUE) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(round(sports_balls)),
         dataset_name = "Mr. Trash Wheel",
         date = str_replace(as.character(date), "1900-01-20", "2020-01-20"),
         date = as.POSIXct(date))

prof_trash_df = read_excel("./Trash Wheel Collection Data.xlsx",
                          sheet = "Professor Trash Wheel",
                          range = "A2:M96",
                          col_names = TRUE) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(dataset_name = "Professor Trash Wheel", year = as.character(year))

combined_trash_df = bind_rows(mr_trash_df, prof_trash_df) %>%
  arrange(date) %>%
  mutate(date = as.Date(date))
view(mr_trash_df)
```

\####looking at the combined_trash_df, mr_trash_df, and prof_trash_df

``` r
skimr::skim(combined_trash_df)
```

|                                                  |                   |
|:-------------------------------------------------|:------------------|
| Name                                             | combined_trash_df |
| Number of rows                                   | 641               |
| Number of columns                                | 15                |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                   |
| Column type frequency:                           |                   |
| character                                        | 3                 |
| Date                                             | 1                 |
| numeric                                          | 11                |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                   |
| Group variables                                  | None              |

Data summary

**Variable type: character**

| skim_variable | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:--------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| month         |         0 |             1 |   3 |   9 |     0 |       13 |          0 |
| year          |         0 |             1 |   4 |   4 |     0 |        9 |          0 |
| dataset_name  |         0 |             1 |  15 |  21 |     0 |        2 |          0 |

**Variable type: Date**

| skim_variable | n_missing | complete_rate | min        | max        | median     | n_unique |
|:--------------|----------:|--------------:|:-----------|:-----------|:-----------|---------:|
| date          |         0 |             1 | 2014-05-16 | 2022-07-29 | 2018-08-14 |      359 |

**Variable type: numeric**

| skim_variable      | n_missing | complete_rate |     mean |       sd |     p0 |     p25 |     p50 |      p75 |      p100 | hist  |
|:-------------------|----------:|--------------:|---------:|---------:|-------:|--------:|--------:|---------:|----------:|:------|
| dumpster           |         0 |          1.00 |   240.78 |   166.88 |   1.00 |   81.00 |  227.00 |   387.00 |    547.00 | ▇▅▅▅▅ |
| weight_tons        |         0 |          1.00 |     3.02 |     0.84 |   0.61 |    2.48 |    3.08 |     3.62 |      5.62 | ▁▅▇▅▁ |
| volume_cubic_yards |         0 |          1.00 |    15.22 |     1.44 |   6.00 |   15.00 |   15.00 |    15.00 |     20.00 | ▁▁▁▇▁ |
| plastic_bottles    |         0 |          1.00 |  2464.81 |  1817.94 | 210.00 | 1110.00 | 2110.00 |  3100.00 |   9830.00 | ▇▆▁▁▁ |
| polystyrene        |         0 |          1.00 |  2088.81 |  1990.25 |  48.00 |  780.00 | 1460.00 |  2870.00 |  11528.00 | ▇▃▁▁▁ |
| cigarette_butts    |         0 |          1.00 | 19663.80 | 28187.00 | 900.00 | 4400.00 | 8000.00 | 23000.00 | 310000.00 | ▇▁▁▁▁ |
| glass_bottles      |         0 |          1.00 |    20.71 |    15.82 |   0.00 |    9.00 |   18.00 |    28.00 |    110.00 | ▇▃▁▁▁ |
| grocery_bags       |         0 |          1.00 |  1217.66 |  1634.36 |  24.00 |  360.00 |  780.00 |  1480.00 |  13450.00 | ▇▁▁▁▁ |
| chip_bags          |         0 |          1.00 |  2405.54 |  3050.01 | 180.00 |  800.00 | 1340.00 |  2684.00 |  20100.00 | ▇▁▁▁▁ |
| sports_balls       |        94 |          0.85 |    12.57 |     9.27 |   0.00 |    6.00 |   11.00 |    18.00 |     56.00 | ▇▅▂▁▁ |
| homes_powered      |        73 |          0.89 |    44.11 |    20.73 |   0.00 |   34.67 |   49.00 |    57.50 |     93.67 | ▂▃▇▅▁ |

``` r
sum(prof_trash_df$weight_tons)
```

    ## [1] 190.12

``` r
sum(mr_trash_df$sports_balls)
```

    ## [1] 6877

`combined_trash_df` has trash collection related data from the
water-wheel vessel that removes trash from the Inner Harbor in
Baltimore, Maryland.The full dumpster is transported to a
waste-to-energy plant with the trash is incinerated to make electricity
for Maryland homes. There are a total of 641 observations after merging
`mr_trash_df` and `prof_trash_df`. Key variables are `date`,
`weight_tons`, `volume_cubic_yards`, `plastic_bottles`, `polystyrene`,
`cigarette_butts`, `glass_bottles`, `grocery_bags`, `chip_bags`,
`sports_balls`, and `home_powered`. The total weight of trash collected
by Professor Trash Wheel was 190.12. The total number of sports balls
collected by Mr. Trash Wheel in 2020 was.

\##Problem3

\####cleaning data

``` r
pols_month = read_csv('fivethirtyeight_datasets/pols-month.csv',
                 col_names = TRUE,
                 show_col_types = FALSE) %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = month.name[as.numeric(month)],
         president = case_when(
           prez_gop == 1 ~ "gop",
           prez_dem == 1 ~ "dem",
           TRUE ~ "NA"
         )) %>%
  select(-c(prez_dem, prez_gop, day)) %>%
  arrange(year, month)

view(pols_month)

snp = read_csv('fivethirtyeight_datasets/snp.csv',
                col_names = TRUE,
                show_col_types = FALSE) %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(month = month.name[as.numeric(month)],
         year = ifelse(as.numeric(year) <= 99 & as.numeric(year) > 15, as.numeric(year) + 1900, as.numeric(year) + 2000),
         year = as.character(year)) %>%
  relocate(year, .before = month) %>% 
  select(-day) %>%
  arrange(year, month)

unemployment = read_csv('fivethirtyeight_datasets/unemployment.csv',
               col_names = TRUE,
               show_col_types = FALSE) %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) %>%
  rename(year = Year) %>%
  mutate(year = as.character(year),
         month = month.name[match(month, month.abb)]) %>%
  arrange(year, month)
```

\####Merging data

``` r
snp_pols_month = pols_month %>% 
  full_join(snp, by = c("year", "month"))

combined_df = snp_pols_month %>%
  full_join(unemployment, by = c("year", "month"))

view(combined_df)
```

`pols_month` includes data about the number of national politicians who
are democratic or republican at any given time (month and year) and the
political affiliation of the current president. `snp` contains
information the closing values of the Standard & Poor’s stock market
index (S&P), often used as a representative measure of stock market as a
whole, by date. `unemployment` shows the unemployment data in percentage
of unemployment by month and year.

After merging all three data, the resulting combined data has a total of
828 observations and 11 variables. Year of data ranges between 1947 and
2015. Key variables include `year`, `month`, `president`, `close`, and
`percent_unemployed`.
