---
title: "p8105_hw2_sy3019"
author: "Soungbin Yim"
date: "2022-10-04"
output: github_document
---

```{r load_libraries}
library(tidyverse)
library(readxl)
library(lubridate)
```


### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
##Problem 2

```{r}
mr_trash_df <- read_excel("Trash Wheel Collection Data.xlsx",
                       sheet = "Mr. Trash Wheel",
                       range = "A2:N550",
                       col_names = TRUE) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(round(sports_balls)),
         dataset_name = "Mr. Trash Wheel",
         date = str_replace(as.character(date), "1900-01-20", "2020-01-20"),
         date = as.POSIXct(date))

prof_trash_df = read_excel("./Trash Wheel Collection Data.xlsx",
                          sheet = "Professor Trash Wheel",
                          range = "A2:M96",
                          col_names = TRUE) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(dataset_name = "Professor Trash Wheel", year = as.character(year))

combined_trash_df = bind_rows(mr_trash_df, prof_trash_df) %>%
  arrange(date) %>%
  mutate(date = as.Date(date))
view(mr_trash_df)
```

####looking at the combined_trash_df, mr_trash_df, and prof_trash_df
```{r}
skimr::skim(combined_trash_df)
sum(prof_trash_df$weight_tons)
sum(mr_trash_df$sports_balls)
```

`combined_trash_df` has trash collection related data from the water-wheel vessel that removes trash from the Inner Harbor in Baltimore, Maryland.The full dumpster is transported to a waste-to-energy plant with the trash is incinerated to make electricity for Maryland homes. There are a total of 641 observations after merging `mr_trash_df` and `prof_trash_df`. Key variables are `date`, `weight_tons`, `volume_cubic_yards`, `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`, `grocery_bags`, `chip_bags`, `sports_balls`, and `home_powered`. The total weight of trash collected by Professor Trash Wheel was `r sum(prof_trash_df$weight_tons)`. The total number of sports balls collected by Mr. Trash Wheel in 2020 was. 


##Problem3 

####cleaning data
```{r}
pols_month = read_csv('fivethirtyeight_datasets/pols-month.csv',
                 col_names = TRUE,
                 show_col_types = FALSE) %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = month.name[as.numeric(month)],
         president = case_when(
           prez_gop == 1 ~ "gop",
           prez_dem == 1 ~ "dem",
           TRUE ~ "NA"
         )) %>%
  select(-c(prez_dem, prez_gop, day)) %>%
  arrange(year, month)

view(pols_month)

snp = read_csv('fivethirtyeight_datasets/snp.csv',
                col_names = TRUE,
                show_col_types = FALSE) %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(month = month.name[as.numeric(month)],
         year = ifelse(as.numeric(year) <= 99 & as.numeric(year) > 15, as.numeric(year) + 1900, as.numeric(year) + 2000),
         year = as.character(year)) %>%
  relocate(year, .before = month) %>% 
  select(-day) %>%
  arrange(year, month)

unemployment = read_csv('fivethirtyeight_datasets/unemployment.csv',
               col_names = TRUE,
               show_col_types = FALSE) %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) %>%
  rename(year = Year) %>%
  mutate(year = as.character(year),
         month = month.name[match(month, month.abb)]) %>%
  arrange(year, month)
```
####Merging data
```{r}
snp_pols_month = pols_month %>% 
  full_join(snp, by = c("year", "month"))

combined_df = snp_pols_month %>%
  full_join(unemployment, by = c("year", "month"))

view(combined_df)
```

`pols_month` includes data about the number of national politicians who are democratic or republican at any given time (month and year) and the political affiliation of the current president.  `snp` contains information the closing values of the Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole, by date. `unemployment` shows the unemployment data in percentage of unemployment by month and year.

After merging all three data, the resulting combined data has a total of `r nrow(combined_df)` observations and `r ncol(combined_df)` variables. Year of data ranges between 1947 and 2015. Key variables include `year`, `month`, `president`, `close`, and `percent_unemployed`.